{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinesecorpus=open('../bishe_e1/data/mycorpus.txt','rt',encoding='utf-8').read()\n",
    "cs_list = list(Chinesecorpus)\n",
    "cs_set_list = list(set(cs_list))\n",
    "cs_set_list.sort(key = cs_list.index)\n",
    "corpus_char=''.join(cs_set_list)   \n",
    "charset=ChineseCharset(corpus_char)            ### 2192 +'<UNK>'+<PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/词向量/totalcase_256d.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.readlines();\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in charset:\n",
    "#     if i in w2v_vocab:\n",
    "#         count += 1\n",
    "# print(count/len(charset))   ## 0.9708295350957156     256词向量中覆盖的字数\n",
    " \n",
    "# print(count,len(charset))   ## 2130 2194             前者是被覆盖的数，后者是字表长度 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2id = {}\n",
    "id2vector = []\n",
    "index = 0\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    line = line.split(' ',1)\n",
    "    id2vector.append(line[1].split(' '))\n",
    "    key2id[line[0]] = index\n",
    "    index += 1\n",
    "#     w2v_vocab.append(line[0])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(key2id) == len(id2vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(key2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "char_embedding = []\n",
    "for i in charset:\n",
    "    index = key2id.get(i,-1)\n",
    "    if index == -1:\n",
    "        vector = np.random.rand(256)\n",
    "    else:\n",
    "#         vector = id2vector[index]\n",
    "        vector = np.array(id2vector[index],dtype='float32')\n",
    "        count += 1\n",
    "        \n",
    "    char_embedding.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/char_embedding.npy',char_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('../data/char_embedding.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2194, 256])\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from torch.utils.data.dataset import *\n",
    "from torch.utils.data.sampler import *  #用于采样\n",
    "from torch.nn.utils.rnn import *\n",
    "import bisect\n",
    "from model import *\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"Joint Extraction of Entities and Relations\")\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "emb_dropout = 0.25\n",
    "\n",
    "clip = 0.35\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "char_kernel_size = 3\n",
    "\n",
    "word_kernel_size = 3\n",
    "\n",
    "emsize = 50\n",
    "\n",
    "char_layers = 3\n",
    "\n",
    "word_layers = 3\n",
    "\n",
    "char_nhid = 50\n",
    "\n",
    "word_nhid = 300\n",
    "\n",
    "log_interval = 100\n",
    "\n",
    "lr = 4\n",
    "\n",
    "aoptim = 'SGD'\n",
    "\n",
    "seed = 1111\n",
    "\n",
    "save = 'model.pt'\n",
    "\n",
    "weight = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")#torch.device代表将torch.Tensor分配到的设备的对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinesecorpus=open('../bishe_e1/data/mycorpus.txt','rt',encoding='utf-8').read()\n",
    "cs_list = list(Chinesecorpus)\n",
    "cs_set_list = list(set(cs_list))\n",
    "cs_set_list.sort(key = cs_list.index)\n",
    "corpus_char=''.join(cs_set_list)   \n",
    "charset=ChineseCharset(corpus_char)            ### 2192 +'<UNK>'+<PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charset = Charset()#定义字符对象\n",
    "# vocab = Vocabulary()#定义词汇对象\n",
    "# vocab.load(\"data/myvocab.txt\")#读文件\n",
    "tag_set = Index()#定义对象\n",
    "tag_set.load(\"../data/my_tag2id.txt\")#读文件  标记-id\n",
    "relation_labels = Index()#定义对象\n",
    "relation_labels.load('../data/my_relation_labels.txt')#读文件   关系标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load('../data/my_train.pk')\n",
    "\n",
    "val_size = int(0.05 * len(train_data))#设置验证集大小\n",
    "train_data, val_data = random_split(train_data, [len(train_data)-val_size, val_size])##torch里的函数 随机切分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2091, 110)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分组排序 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(data, breakpoints):# 把数据集按照句子长度分组#data:包含三部分 句子中每个词的id 句子中每个词对应的char的id 句子对应的实体id\n",
    "    groups = [[] for _ in range(len(breakpoints)+1)]\n",
    "    for idx, item in enumerate(data):\n",
    "        i = bisect.bisect_left(breakpoints, len(item[0]))\n",
    "        groups[i].append(idx)\n",
    "    data_groups = [Subset(data, g) for g in groups]  #Subset是torch.utils.data.dataset中的\n",
    "    return data_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_groups = group(train_data, [50, 100, 150, 200, 250])\n",
    "val_data_groups = group(val_data, [50, 100, 150, 200, 250])    ####一个分组排序的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1266, 402, 65, 21, 95, 124, 210, 202, 4, 5, 6, 19, 20, 21, 688, 23, 23, 335, 186, 336, 325, 43, 44, 45, 46, 47, 48, 49, 50, 51, 9, 10, 118, 8, 56, 56, 56, 119, 52], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 27, 29, 0, 0, 0, 0, 26, 28, 28, 28, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(train_data_groups[0][1])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采样与填充 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupBatchRandomSampler(object):##每一组的句子长度不同 分别建采样器进行随机采样\n",
    "    def __init__(self, data_groups, batch_size, drop_last):\n",
    "        self.batch_indices = []\n",
    "        for data_group in data_groups:\n",
    "            self.batch_indices.extend(list(BatchSampler(SubsetRandomSampler(data_group.indices),\n",
    "                                                        batch_size, drop_last=drop_last)))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.batch_indices[i] for i in torch.randperm(len(self.batch_indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_indices, data):  #分batch   data有三部分   返回三部分的batch\n",
    "    #print(batch_indices,len(data))\n",
    "    batch = [data[idx] for idx in batch_indices]\n",
    "    sorted_batch = sorted(batch, key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tags = zip(*sorted_batch)\n",
    "#     print([len(s) for s in sentences])\n",
    "\n",
    "    padded_sentences, lengths = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in sentences],enforce_sorted=False),  #文本长度对齐\n",
    "                                                    batch_first=True, padding_value=charset[\"<pad>\"])\n",
    "    padded_tags, _ = pad_packed_sequence(pack_sequence([torch.LongTensor(_) for _ in tags],enforce_sorted=False),\n",
    "                                         batch_first=True, padding_value=tag_set[\"O\"])\n",
    "\n",
    "    return padded_sentences.to(device),  padded_tags.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedding = torch.Tensor(np.load('../data/char_embedding.npy'))\n",
    "char_embedding_size = char_embedding.size(1)\n",
    "\n",
    "\n",
    "# word_embeddings = torch.tensor(np.load(\"data/NYT_CoType/word2vec.vectors.npy\"))      #将词向量转换为张量 47463*300\n",
    "# word_embedding_size = word_embeddings.size(1)\n",
    "# pad_embedding = torch.empty(1, word_embedding_size).uniform_(-0.5, 0.5)  #随机初始化 1*word_embedding_size 大小的张量 取值在-0.5~0.5之间\n",
    "# unk_embedding = torch.empty(1, word_embedding_size).uniform_(-0.5, 0.5)\n",
    "# word_embeddings = torch.cat([pad_embedding, unk_embedding, word_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_embedding) == len(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = [1,2,3,4,5]\n",
    "sentences, targets, lengths = get_batch(batch_indices, train_data) #分batch\n",
    "\n",
    "# sentences[0]\n",
    "\n",
    "# charset[20],charset[21],charset[522],charset[23],charset[88]\n",
    "\n",
    "# charset['鹰']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 276)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[4]),len(targets[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型搭建 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_channels = [char_embedding_size] + [char_nhid] * char_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, targets, lengths = get_batch([0,1,2,3,4], train_data)\n",
    "# out = Model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"model.pt\"):      #是否存在已经构造好的模型\n",
    "    model=torch.load('model.pt')\n",
    "#——————————搭建模型————————————\n",
    "else:\n",
    "    model = Model( weight=char_embedding,\n",
    "                  char_embedding_size=char_embedding_size, char_channels=char_channels,\n",
    "                  char_kernel_size=char_kernel_size, num_tag=len(tag_set), dropout=dropout,\n",
    "                  emb_dropout=emb_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.1018, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [weight] * len(tag_set)   #生成一维向量 初始化值为arg.weight 维度为len(tag_set)\n",
    "weight[tag_set[\"O\"]] = 1     #\"O\"标签对应的权值为1\n",
    "\n",
    "\n",
    "weight = torch.tensor(weight).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IR LAB\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss(weight, size_average=False)      #定义的损失函数\n",
    "optimizer = getattr(optim, aoptim)(model.parameters(), lr=lr)  #getattr 获取torch.optim对象的属性值 默认是SGD(随机梯度下降)   得到优化器的损失函数(模型参数)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()    #torch的模型训练\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    sampler = GroupBatchRandomSampler(train_data_groups, batch_size, drop_last=False)#采样器是定义的采样器对象 按组分batch分别采样\n",
    "\n",
    "    for idx, batch_indices in enumerate(sampler):\n",
    "        sentences, targets, lengths = get_batch(batch_indices, train_data) #分batch\n",
    "    #     print(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(sentences)  #词级别和字符级别建模\n",
    "        output = pack_padded_sequence(output, lengths, batch_first=True,enforce_sorted=False).data #文本长度对齐\n",
    "        targets = pack_padded_sequence(targets, lengths, batch_first=True,enforce_sorted=False).data #将标签的编码长度对齐\n",
    "        loss = criterion(output, targets)  #损失函数\n",
    "        loss.backward()\n",
    "        if clip > 0:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        count += len(targets)\n",
    "#         print('Hello world!!!')\n",
    "        if (idx+1) % log_interval == 0:\n",
    "            cur_loss = total_loss / count\n",
    "            elapsed = time.time() - start_time\n",
    "            percent = ((epoch-1)*len(sampler)+(idx+1))/(epochs*len(sampler))\n",
    "            remaining = elapsed / percent - elapsed\n",
    "            print(\"| Epoch {:2d}/{:2d} | Batch {:5d}/{:5d} | Elapsed Time {:s} | Remaining Time {:s} | \"\n",
    "                  \"lr {:4.2e} | Loss {:5.3f} |\".format(epoch, epochs, idx+1, len(sampler), time_display(elapsed),\n",
    "                                                       time_display(remaining), lr, cur_loss))\n",
    "            total_loss = 0\n",
    "            count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_groups):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0.000000001\n",
    "    TP = 0.000000001\n",
    "    TP_FP = 0.000000001\n",
    "    TP_FN = 0.000000001\n",
    "    with torch.no_grad():\n",
    "        for batch_indices in GroupBatchRandomSampler(data_groups, batch_size, drop_last=False):\n",
    "            sentences,targets, lengths = get_batch(batch_indices, train_data)\n",
    "            output = model(sentences)\n",
    "            tp, tp_fp, tp_fn = measure(output, targets, lengths,sentences)\n",
    "            TP += tp\n",
    "            TP_FP += tp_fp\n",
    "            TP_FN += tp_fn\n",
    "            output = pack_padded_sequence(output, lengths, batch_first=True).data\n",
    "            targets = pack_padded_sequence(targets, lengths, batch_first=True).data\n",
    "            loss = criterion(output, targets)\n",
    "            total_loss += loss.item()\n",
    "            count += len(targets)\n",
    "            print(count,TP_FP,TP_FN)\n",
    "    return total_loss / count, TP/TP_FP, TP/TP_FN, 2*TP/(TP_FP+TP_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure(output, targets, lengths,sentences)\n",
    "def measure(output, targets, lengths,sentences):\n",
    "    assert output.size(0) == targets.size(0) and targets.size(0) == lengths.size(0)\n",
    "    tp = 0\n",
    "    tp_fp = 0\n",
    "    tp_fn = 0\n",
    "    batch_size = output.size(0)\n",
    "    output = torch.argmax(output, dim=-1)\n",
    "    for i in range(batch_size):\n",
    "        sentence = sentences[i]\n",
    "        length = lengths[i]\n",
    "        out = output[i][:length].tolist()\n",
    "        target = targets[i][:length].tolist()\n",
    "        out_triplets = song_get_triplets(out,sentence)\n",
    "        print(\"out:\",out_triplets)\n",
    "        tp_fp += len(out_triplets)\n",
    "        target_triplets = song_get_triplets(target,sentence)\n",
    "        print(\"target:\",target_triplets)\n",
    "        tp_fn += len(target_triplets)\n",
    "        for target_triplet in target_triplets:\n",
    "            for out_triplet in out_triplets:\n",
    "                if out_triplet == target_triplet:\n",
    "                    tp += 1\n",
    "    return tp, tp_fp, tp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def song_get_triplets(tags,outset):\n",
    "    outsent = charset\n",
    "#     outsent = out[0]\n",
    "#     tags = out[1]\n",
    "#     assert len(outsent) == len(tags)\n",
    "    temp = {}\n",
    "    triplets = []\n",
    "    for idx, tag in enumerate(tags):\n",
    "        if tag == tag_set[\"O\"]:\n",
    "            continue\n",
    "    #     entity=[]\n",
    "        pos, relation_label, role = tag_set[tag].split(\"-\")\n",
    "        if pos == \"B\" or pos == \"S\":\n",
    "            entity=[]\n",
    "            entity.append(idx)\n",
    "        if pos==\"I\" or pos==\"E\":\n",
    "            try:\n",
    "                entity.append(idx)\n",
    "            except UnboundLocalError:\n",
    "                entity = []\n",
    "                entity.append(idx)\n",
    "        if pos==\"S\" or pos==\"E\":\n",
    "            if relation_label not in temp:\n",
    "                temp[relation_label] = [[], []]\n",
    "            temp[relation_label][int(role) - 1].append(entity)\n",
    "    try:\n",
    "        label = list(temp.keys())[0]\n",
    "    except IndexError:\n",
    "        triplets.append([])\n",
    "        triplets.append([])\n",
    "        triplets.append([])\n",
    "        return triplets\n",
    "#     print(label)\n",
    "    entitys = temp[label]\n",
    "#     print('entitys:',entitys)\n",
    "\n",
    "    entity_tmp = entitys[0]   \n",
    "    if len(entity_tmp) == 0:\n",
    "        entity1 = []\n",
    "    else:\n",
    "        entity1 = entity_tmp[0]\n",
    "        \n",
    "    entity_tmp = entitys[1]  \n",
    "    if len(entity_tmp) == 0:\n",
    "        entity2 = []\n",
    "    else:\n",
    "        entity2 = entity_tmp[0]\n",
    "\n",
    "\n",
    "    entity1_word = []  \n",
    "#     print(entity1)\n",
    "    for i in entity1:\n",
    "#         print(outset[i])\n",
    "        entity1_word.append(outsent[int(outset[i])])\n",
    "#     print(entity1_word)\n",
    "    entity1_word = ''.join(entity1_word)\n",
    "#     print(entity1_word)\n",
    "\n",
    "    entity2_word = []\n",
    "    for i in entity2:\n",
    "        entity2_word.append(outsent[int(outset[i])])\n",
    "#     print(entity2_word)\n",
    "    entity2_word = ''.join(entity2_word)\n",
    "#     print(entity2_word)\n",
    "    \n",
    "    triplets.append(entity1_word)\n",
    "    triplets.append(label)\n",
    "    triplets.append(entity2_word)\n",
    "    \n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------\n",
      "out: ['某某', 'provide_shelter_for', '某某']\n",
      "target: ['员当场', 'posess', '条、吸']\n",
      "out: ['翁某某', 'provide_shelter_for', '']\n",
      "target: ['获的用', 'posess', '丙胺和']\n",
      "out: ['罗××', 'provide_shelter_for', '黄××']\n",
      "target: ['黄××', 'traffic_in', '海洛因']\n",
      "out: ['李某某', 'provide_shelter_for', '陈某']\n",
      "target: ['陈美燕', 'sell_drugs_to', '邹某某']\n",
      "out: ['罗某', 'provide_shelter_for', '']\n",
      "target: ['罗某', 'traffic_in', '冰毒']\n",
      "out: ['刘某', 'provide_shelter_for', '刘某']\n",
      "target: ['刘某', 'posess', '氯胺酮']\n",
      "out: ['曾某', 'provide_shelter_for', '林某某']\n",
      "target: ['曾某', 'provide_shelter_for', '林某某']\n",
      "out: ['周某', 'provide_shelter_for', '周某基苯丙']\n",
      "target: ['周某', 'traffic_in', '麻果']\n",
      "out: ['王某', 'provide_shelter_for', '王某']\n",
      "target: ['王某甲', 'provide_shelter_for', '王某']\n",
      "out: ['谭某', 'provide_shelter_for', '唐某某']\n",
      "target: ['谭某', 'provide_shelter_for', '廖某']\n",
      "out: ['某', 'provide_shelter_for', '胡某']\n",
      "target: ['丁某', 'traffic_in', '冰毒']\n",
      "out: ['潘某某', 'provide_shelter_for', '']\n",
      "target: ['潘某某', 'posess', '神仙水']\n",
      "out: ['张×', 'provide_shelter_for', '刘×']\n",
      "target: ['张×', 'provide_shelter_for', '史×']\n",
      "out: ['伍某', 'provide_shelter_for', '陈某某']\n",
      "target: ['伍某大', 'sell_drugs_to', '陈某某']\n",
      "out: ['谢某', 'provide_shelter_for', '李某']\n",
      "target: ['谢某', 'provide_shelter_for', '彭某']\n",
      "out: ['许某某某某', 'provide_shelter_for', '许某某某某']\n",
      "target: ['金某某', 'provide_shelter_for', '朴某某']\n",
      "2596.000000001 48.000000001 48.000000001\n",
      "out: ['李某某', 'provide_shelter_for', '李某某']\n",
      "target: ['××又', 'sell_drugs_to', '家过夜']\n",
      "out: ['刘某某苯丙', 'provide_shelter_for', '']\n",
      "target: ['胡修忠', 'traffic_in', '冰毒']\n",
      "out: ['许某某', 'provide_shelter_for', '许某某']\n",
      "target: ['许某某', 'sell_drugs_to', '蒋某某']\n",
      "out: ['许某某', 'provide_shelter_for', '某某']\n",
      "target: ['大黄毛', 'traffic_in', '冰毒']\n",
      "out: ['邓某某', 'provide_shelter_for', '李某']\n",
      "target: ['邓某某', 'posess', '甲基苯丙胺']\n",
      "out: ['吴某某苯丙', 'provide_shelter_for', '吴某某']\n",
      "target: ['吴某某', 'traffic_in', '甲基苯丙胺']\n",
      "out: ['莫某某', 'provide_shelter_for', '王某']\n",
      "target: ['莫某某', 'posess', '甲基苯丙胺']\n",
      "out: ['莫某某', 'provide_shelter_for', '王某']\n",
      "target: ['莫某某', 'provide_shelter_for', '陈某']\n",
      "out: ['宋某某', 'provide_shelter_for', '段某某某']\n",
      "target: ['宋某某', 'provide_shelter_for', '李某']\n",
      "out: ['王某', 'provide_shelter_for', '符某某']\n",
      "target: ['王某', 'sell_drugs_to', '符某某']\n",
      "out: ['吉某某', 'provide_shelter_for', '孙某某某']\n",
      "target: ['吉地某某', 'sell_drugs_to', '桑某']\n",
      "out: ['徐某某', 'provide_shelter_for', '刘某']\n",
      "target: ['徐某某', 'provide_shelter_for', '刘某']\n",
      "out: ['董某', 'provide_shelter_for', '']\n",
      "target: ['董某', 'posess', '甲基苯丙胺']\n",
      "out: ['吴某某苯', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'posess', '冰毒']\n",
      "out: ['王某', 'provide_shelter_for', '赵某基']\n",
      "target: ['王某', 'sell_drugs_to', '许某']\n",
      "out: ['匡某', 'provide_shelter_for', '曹某']\n",
      "target: ['匡某', 'sell_drugs_to', '曹某甲']\n",
      "out: ['黄某某某', 'provide_shelter_for', '黄某某']\n",
      "target: ['黄某某', 'provide_shelter_for', '覃某某']\n",
      "out: ['江某某某某某', 'provide_shelter_for', '江某某某某某']\n",
      "target: ['温某某', 'posess', '麻古']\n",
      "out: ['许XX某', 'provide_shelter_for', '许XX某']\n",
      "target: ['明某', 'posess', '甲基苯丙胺片剂']\n",
      "out: ['韩×', 'provide_shelter_for', '崔××']\n",
      "target: ['韩×', 'provide_shelter_for', '崔××']\n",
      "out: ['贺某', 'provide_shelter_for', '']\n",
      "target: ['贺某', 'provide_shelter_for', '孟元亮']\n",
      "out: ['陆某某', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'posess', '冰毒']\n",
      "out: ['曾某某某某某某某某', 'provide_shelter_for', '王某某']\n",
      "target: ['曾某某', 'provide_shelter_for', '王某某']\n",
      "out: ['徐某', 'provide_shelter_for', '']\n",
      "target: ['徐某', 'provide_shelter_for', '赵某']\n",
      "6494.000000001 120.00000000099999 120.00000000099999\n",
      "out: ['郄某某', 'provide_shelter_for', '郄某某']\n",
      "target: ['平山县', 'sell_drugs_to', '一天，']\n",
      "out: ['张某', 'provide_shelter_for', '赵某']\n",
      "target: ['年4', 'sell_drugs_to', '2个给']\n",
      "out: ['宋xxxxxxx', 'provide_shelter_for', '陈xx']\n",
      "target: ['宋xx', 'posess', '甲基苯丙胺']\n",
      "out: ['段某某', 'provide_shelter_for', '段某某']\n",
      "target: ['根按照', 'sell_drugs_to', '阮长敏']\n",
      "out: ['马某某某某某某某', 'provide_shelter_for', '马某某某某某某某']\n",
      "target: ['马某', 'provide_shelter_for', '喻某某']\n",
      "out: ['马某某某某某某某', 'provide_shelter_for', '马某某某某某某某']\n",
      "target: ['马某', 'provide_shelter_for', '宾某']\n",
      "out: ['梁xx洛', 'provide_shelter_for', '梁xx']\n",
      "target: ['，用刀', 'traffic_in', '量后，']\n",
      "out: ['钟某', 'provide_shelter_for', '杨某某']\n",
      "target: ['钟某', 'provide_shelter_for', '陈某乙']\n",
      "out: ['陈xx', 'provide_shelter_for', '陈xx']\n",
      "target: ['赵xx', 'provide_shelter_for', '彭xx']\n",
      "out: ['朱某某基苯', 'provide_shelter_for', '朱某某基苯']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['冯某某', 'provide_shelter_for', '冯某某']\n",
      "target: ['冯某某', 'sell_drugs_to', '王某某']\n",
      "out: ['朱某某基苯丙基苯', 'provide_shelter_for', '']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺片剂']\n",
      "out: [[], [], []]\n",
      "target: ['胡长友', 'posess', '大麻']\n",
      "out: ['张某', 'provide_shelter_for', '张某']\n",
      "target: ['张某', 'posess', '甲基苯丙胺']\n",
      "out: ['武某某', 'provide_shelter_for', '武某某']\n",
      "target: ['武某某', 'posess', '咖啡因']\n",
      "out: ['陈某', 'provide_shelter_for', '陈某']\n",
      "target: ['陈某湘', 'provide_shelter_for', '彭某花']\n",
      "out: ['方某', 'provide_shelter_for', '罗某某xxxxxxxx']\n",
      "target: ['方某', 'provide_shelter_for', '潘某']\n",
      "out: ['杨某', 'provide_shelter_for', '简×']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['刘某', 'provide_shelter_for', '']\n",
      "target: ['刘某', 'traffic_in', '甲盐酸曲马多']\n",
      "out: ['张某', 'provide_shelter_for', '彭某']\n",
      "target: ['张某', 'provide_shelter_for', '彭某']\n",
      "out: ['黄某某', 'provide_shelter_for', '朱某某']\n",
      "target: ['黄某某', 'sell_drugs_to', '朱某某']\n",
      "out: ['牟某某', 'provide_shelter_for', '牟某某']\n",
      "target: ['牟某某', 'provide_shelter_for', '黄金林']\n",
      "out: ['代某洛', 'provide_shelter_for', '谢某洛某洛']\n",
      "target: ['代某', 'sell_drugs_to', '谢某']\n",
      "out: ['龙某基', 'provide_shelter_for', '']\n",
      "target: ['龙某', 'posess', '麻古']\n",
      "out: ['吴某某', 'provide_shelter_for', '钟某']\n",
      "target: ['吴某某', 'traffic_in', '冰毒']\n",
      "out: ['代某某', 'provide_shelter_for', '邱某某']\n",
      "target: ['代某某', 'provide_shelter_for', '赖某']\n",
      "out: ['胡某某xxx', 'provide_shelter_for', '胡某某xxx']\n",
      "target: ['胡某某', 'provide_shelter_for', '夏某某']\n",
      "out: ['吉某', 'provide_shelter_for', '李某某']\n",
      "target: ['李某某', 'provide_shelter_for', '姜某']\n",
      "out: ['左某XXX', 'provide_shelter_for', '左某XXX']\n",
      "target: ['项某', 'provide_shelter_for', '张某']\n",
      "out: ['郑某某', 'provide_shelter_for', '王某']\n",
      "target: ['郑某某', 'provide_shelter_for', '王某']\n",
      "11798.000000001 210.000000001 210.000000001\n",
      "out: ['刘某', 'provide_shelter_for', '莫某']\n",
      "target: ['获，', 'provide_shelter_for', '后锡']\n",
      "out: ['陈某某', 'provide_shelter_for', '杜某']\n",
      "target: ['90', 'provide_shelter_for', '90']\n",
      "out: ['梁某', 'provide_shelter_for', '梁某洛']\n",
      "target: ['梁某', 'posess', '冰毒']\n",
      "out: ['曾某某', 'provide_shelter_for', '黎某']\n",
      "target: ['氯胺', 'posess', '']\n",
      "out: ['卢某', 'provide_shelter_for', '陈某']\n",
      "target: ['在被', 'sell_drugs_to', '随即']\n",
      "out: ['杨某某', 'provide_shelter_for', '钟某']\n",
      "target: ['阿俊', 'traffic_in', '冰毒']\n",
      "out: ['钟某某XXXXXX', 'provide_shelter_for', '钟某某XXXXXX']\n",
      "target: ['钟某某', 'posess', '海洛因']\n",
      "out: ['何某某', 'provide_shelter_for', '唐某']\n",
      "target: ['何某某', 'sell_drugs_to', '朱某']\n",
      "out: ['蔡某某', 'provide_shelter_for', '季某某']\n",
      "target: ['季某某', 'traffic_in', '冰毒']\n",
      "out: [[], [], []]\n",
      "target: ['伊布卡·杜库', 'posess', '海洛因']\n",
      "out: ['夏某某基丙', 'provide_shelter_for', '吕某某某某某某']\n",
      "target: ['纳某某', 'sell_drugs_to', '吕某某']\n",
      "out: ['邢某某', 'provide_shelter_for', '陈某']\n",
      "target: ['邢某某', 'provide_shelter_for', '田某线']\n",
      "out: ['黄某洛', 'provide_shelter_for', '罗某']\n",
      "target: ['黄某', 'sell_drugs_to', '罗某']\n",
      "out: ['覃某', 'provide_shelter_for', '林某']\n",
      "target: ['覃某', 'traffic_in', '氯胺酮']\n",
      "out: ['王XX', 'provide_shelter_for', '宋X']\n",
      "target: ['王XX', 'provide_shelter_for', '向X']\n",
      "out: ['徐某', 'provide_shelter_for', '孙某某']\n",
      "target: ['徐某', 'sell_drugs_to', '孙某某']\n",
      "out: ['程某某', 'provide_shelter_for', '程某某']\n",
      "target: ['程明开程某某', 'provide_shelter_for', '程某3']\n",
      "out: ['何某', 'provide_shelter_for', '张某']\n",
      "target: ['何某', 'traffic_in', '冰毒']\n",
      "out: ['谢某', 'provide_shelter_for', '张某']\n",
      "target: ['谢某', 'provide_shelter_for', '李某甲']\n",
      "out: ['韩某某', 'provide_shelter_for', '阳某某']\n",
      "target: ['韩某某', 'sell_drugs_to', '刘某某']\n",
      "out: ['张某甲', 'provide_shelter_for', '娄某']\n",
      "target: ['张某甲', 'provide_shelter_for', '娄某']\n",
      "out: ['吴某', 'provide_shelter_for', '']\n",
      "target: ['吴某', 'posess', '甲基苯丙胺']\n",
      "out: ['郭某', 'provide_shelter_for', '苏某']\n",
      "target: ['郭某', 'provide_shelter_for', '刘某某']\n",
      "15830.000000001 279.000000001 279.000000001\n",
      "out: ['吴某某苯丙', 'provide_shelter_for', '江XX']\n",
      "target: ['吴某某', 'posess', '甲基苯丙胺']\n",
      "15957.000000001 282.000000001 282.000000001\n",
      "out: ['林某', 'provide_shelter_for', '陈某某']\n",
      "target: ['吸食甲', 'provide_shelter_for', '查获陈']\n",
      "out: ['林某', 'provide_shelter_for', '龙某']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: ['号门口', 'sell_drugs_to', '深圳']\n",
      "out: ['叶某', 'provide_shelter_for', '王某']\n",
      "target: ['法鉴', 'sell_drugs_to', '份。当']\n",
      "out: ['肖某', 'provide_shelter_for', '张某']\n",
      "target: ['肖某', 'sell_drugs_to', '张某丙']\n",
      "out: ['朱某', 'provide_shelter_for', '朱某某']\n",
      "target: ['朱某某', 'provide_shelter_for', '朱某1']\n",
      "out: ['姚某某', 'provide_shelter_for', '姚某某']\n",
      "target: ['在房间', 'provide_shelter_for', '在长沙']\n",
      "out: ['章×××××', 'provide_shelter_for', '章×××××']\n",
      "target: ['汪章胜', 'posess', '大麻叶']\n",
      "out: ['邓某基', 'provide_shelter_for', '']\n",
      "target: ['邓某', 'posess', '甲基苯丙胺']\n",
      "out: ['曹某', 'provide_shelter_for', '罗某']\n",
      "target: ['曹某', 'provide_shelter_for', '张某\"4']\n",
      "out: ['秦xxxx', 'provide_shelter_for', '秦xxxx']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['许某某XXX', 'provide_shelter_for', '许某某XXX']\n",
      "target: ['钱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['李某某', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'posess', '甲基苯丙胺']\n",
      "out: ['郑某某某', 'provide_shelter_for', '苏某某洛洛洛']\n",
      "target: ['郑某', 'sell_drugs_to', '苏某某']\n",
      "out: ['甘某', 'provide_shelter_for', '赵某']\n",
      "target: ['甘某', 'provide_shelter_for', '赵某']\n",
      "out: ['刘某某苯', 'provide_shelter_for', '刘某某苯']\n",
      "target: ['刘某某', 'posess', '甲基苯丙胺']\n",
      "out: ['简某某', 'provide_shelter_for', '杨某某']\n",
      "target: ['简某某', 'provide_shelter_for', '杨某某']\n",
      "19128.000000001 330.000000001 330.000000001\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "| End of Epoch  1 | Elapsed Time    00:00:31 | Validation Loss 1.234 | Precision 0.364 | Recall 0.364 | F1 0.364 |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "out: ['某某某某某', 'provide_shelter_for', '']\n",
      "target: ['平山县', 'sell_drugs_to', '一天，']\n",
      "out: ['', 'traffic_in', '海洛因某某']\n",
      "target: ['年4', 'sell_drugs_to', '2个给']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['宋xx', 'posess', '甲基苯丙胺']\n",
      "out: ['段某某', 'provide_shelter_for', '']\n",
      "target: ['根按照', 'sell_drugs_to', '阮长敏']\n",
      "out: ['某某', 'provide_shelter_for', '']\n",
      "target: ['马某', 'provide_shelter_for', '喻某某']\n",
      "out: ['马某某', 'provide_shelter_for', '']\n",
      "target: ['马某', 'provide_shelter_for', '宾某']\n",
      "out: ['', 'traffic_in', '海洛因x']\n",
      "target: ['，用刀', 'traffic_in', '量后，']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['钟某', 'provide_shelter_for', '陈某乙']\n",
      "out: ['', 'posess', '赵胺']\n",
      "target: ['赵xx', 'provide_shelter_for', '彭xx']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺片剂']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['冯某', 'provide_shelter_for', '']\n",
      "target: ['冯某某', 'sell_drugs_to', '王某某']\n",
      "out: ['', 'posess', '甲基苯丙胺酮']\n",
      "target: ['胡长友', 'posess', '大麻']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['武某某', 'posess', '咖啡因']\n",
      "out: ['张某', 'provide_shelter_for', '']\n",
      "target: ['张某', 'posess', '甲基苯丙胺']\n",
      "out: ['陈某', 'provide_shelter_for', '']\n",
      "target: ['陈某湘', 'provide_shelter_for', '彭某花']\n",
      "out: ['方某甲', 'provide_shelter_for', '']\n",
      "target: ['方某', 'provide_shelter_for', '潘某']\n",
      "out: ['杨某甲基苯丙胺', 'provide_shelter_for', '']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['刘某', 'provide_shelter_for', '']\n",
      "target: ['刘某', 'traffic_in', '甲盐酸曲马多']\n",
      "out: ['海某', 'provide_shelter_for', '']\n",
      "target: ['张某', 'provide_shelter_for', '彭某']\n",
      "out: ['', 'posess', '黄基苯丙胺']\n",
      "target: ['黄某某', 'sell_drugs_to', '朱某某']\n",
      "out: ['', 'posess', '麻古']\n",
      "target: ['牟某某', 'provide_shelter_for', '黄金林']\n",
      "out: ['代某', 'provide_shelter_for', '']\n",
      "target: ['代某', 'sell_drugs_to', '谢某']\n",
      "out: ['龙某', 'provide_shelter_for', '']\n",
      "target: ['龙某', 'posess', '麻古']\n",
      "out: ['吴某某忠忠', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'traffic_in', '冰毒']\n",
      "out: ['代某某某', 'provide_shelter_for', '']\n",
      "target: ['代某某', 'provide_shelter_for', '赖某']\n",
      "out: ['胡某某', 'provide_shelter_for', '']\n",
      "target: ['胡某某', 'provide_shelter_for', '夏某某']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'provide_shelter_for', '姜某']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['项某', 'provide_shelter_for', '张某']\n",
      "out: ['郑某某', 'provide_shelter_for', '']\n",
      "target: ['郑某某', 'provide_shelter_for', '王某']\n",
      "5304.000000001 90.000000001 90.000000001\n",
      "out: ['某甲基苯丙胺', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'posess', '甲基苯丙胺']\n",
      "5431.000000001 93.000000001 93.000000001\n",
      "out: ['某基苯丙某', 'provide_shelter_for', '']\n",
      "target: ['吸食甲', 'provide_shelter_for', '查获陈']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['法鉴', 'sell_drugs_to', '份。当']\n",
      "out: ['李某', 'provide_shelter_for', '']\n",
      "target: ['号门口', 'sell_drugs_to', '深圳']\n",
      "out: ['某因', 'provide_shelter_for', '']\n",
      "target: ['肖某', 'sell_drugs_to', '张某丙']\n",
      "out: ['朱某', 'provide_shelter_for', '']\n",
      "target: ['朱某某', 'provide_shelter_for', '朱某1']\n",
      "out: ['某某某基苯丙胺', 'provide_shelter_for', '']\n",
      "target: ['在房间', 'provide_shelter_for', '在长沙']\n",
      "out: ['', 'posess', '甲基苯丙胺胺']\n",
      "target: ['汪章胜', 'posess', '大麻叶']\n",
      "out: ['黄某', 'provide_shelter_for', '']\n",
      "target: ['邓某', 'posess', '甲基苯丙胺']\n",
      "out: ['张某', 'provide_shelter_for', '']\n",
      "target: ['曹某', 'provide_shelter_for', '张某\"4']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['钱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['李某因甲基苯丙胺', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'posess', '甲基苯丙胺']\n",
      "out: ['郑某某某', 'provide_shelter_for', '']\n",
      "target: ['郑某', 'sell_drugs_to', '苏某某']\n",
      "out: ['甘某某某', 'provide_shelter_for', '']\n",
      "target: ['甘某', 'provide_shelter_for', '赵某']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['刘某某', 'posess', '甲基苯丙胺']\n",
      "out: ['某某某', 'provide_shelter_for', '']\n",
      "target: ['简某某', 'provide_shelter_for', '杨某某']\n",
      "8602.000000001 141.000000001 141.000000001\n",
      "out: ['某锋因', 'traffic_in', '某锋因']\n",
      "target: ['员当场', 'posess', '条、吸']\n",
      "out: ['某果', 'provide_shelter_for', '']\n",
      "target: ['获的用', 'posess', '丙胺和']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['黄××', 'traffic_in', '海洛因']\n",
      "out: ['某某', 'provide_shelter_for', '']\n",
      "target: ['陈美燕', 'sell_drugs_to', '邹某某']\n",
      "out: ['冰某', 'provide_shelter_for', '']\n",
      "target: ['罗某', 'traffic_in', '冰毒']\n",
      "out: ['', 'posess', '刘胺酮胺']\n",
      "target: ['刘某', 'posess', '氯胺酮']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['曾某', 'provide_shelter_for', '林某某']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['周某', 'traffic_in', '麻果']\n",
      "out: ['甲', 'provide_shelter_for', '']\n",
      "target: ['王某甲', 'provide_shelter_for', '王某']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['谭某', 'provide_shelter_for', '廖某']\n",
      "out: [[], [], []]\n",
      "target: ['丁某', 'traffic_in', '冰毒']\n",
      "out: ['潘某某', 'provide_shelter_for', '']\n",
      "target: ['潘某某', 'posess', '神仙水']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['张×', 'provide_shelter_for', '史×']\n",
      "out: ['伍某', 'provide_shelter_for', '']\n",
      "target: ['伍某大', 'sell_drugs_to', '陈某某']\n",
      "out: ['彭某', 'provide_shelter_for', '']\n",
      "target: ['谢某', 'provide_shelter_for', '彭某']\n",
      "out: ['某某某', 'provide_shelter_for', '']\n",
      "target: ['金某某', 'provide_shelter_for', '朴某某']\n",
      "11198.000000001 189.000000001 189.000000001\n",
      "out: ['赵某', 'provide_shelter_for', '']\n",
      "target: ['获，', 'provide_shelter_for', '后锡']\n",
      "out: ['陈某', 'provide_shelter_for', '']\n",
      "target: ['90', 'provide_shelter_for', '90']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['梁某', 'posess', '冰毒']\n",
      "out: ['曾某某某', 'provide_shelter_for', '']\n",
      "target: ['氯胺', 'posess', '']\n",
      "out: ['', 'traffic_in', '海洛因某']\n",
      "target: ['在被', 'sell_drugs_to', '随即']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['阿俊', 'traffic_in', '冰毒']\n",
      "out: ['某某', 'provide_shelter_for', '']\n",
      "target: ['钟某某', 'posess', '海洛因']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['何某某', 'sell_drugs_to', '朱某']\n",
      "out: ['蔡某', 'provide_shelter_for', '']\n",
      "target: ['季某某', 'traffic_in', '冰毒']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['伊布卡·杜库', 'posess', '海洛因']\n",
      "out: ['纳某某基苯丙胺', 'provide_shelter_for', '']\n",
      "target: ['纳某某', 'sell_drugs_to', '吕某某']\n",
      "out: ['邢某某', 'provide_shelter_for', '']\n",
      "target: ['邢某某', 'provide_shelter_for', '田某线']\n",
      "out: ['黄某', 'provide_shelter_for', '']\n",
      "target: ['黄某', 'sell_drugs_to', '罗某']\n",
      "out: ['覃某酮', 'provide_shelter_for', '']\n",
      "target: ['覃某', 'traffic_in', '氯胺酮']\n",
      "out: [[], [], []]\n",
      "target: ['王XX', 'provide_shelter_for', '向X']\n",
      "out: ['徐某', 'provide_shelter_for', '']\n",
      "target: ['徐某', 'sell_drugs_to', '孙某某']\n",
      "out: ['程某某因弟', 'provide_shelter_for', '']\n",
      "target: ['程明开程某某', 'provide_shelter_for', '程某3']\n",
      "out: ['何某', 'provide_shelter_for', '']\n",
      "target: ['何某', 'traffic_in', '冰毒']\n",
      "out: ['谢某', 'provide_shelter_for', '']\n",
      "target: ['谢某', 'provide_shelter_for', '李某甲']\n",
      "out: ['韩某某', 'provide_shelter_for', '']\n",
      "target: ['韩某某', 'sell_drugs_to', '刘某某']\n",
      "out: ['张某甲', 'provide_shelter_for', '']\n",
      "target: ['张某甲', 'provide_shelter_for', '娄某']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: ['吴某', 'posess', '甲基苯丙胺']\n",
      "out: ['郭某', 'provide_shelter_for', '']\n",
      "target: ['郭某', 'provide_shelter_for', '刘某某']\n",
      "15230.000000001 258.000000001 258.000000001\n",
      "out: ['李某某', 'provide_shelter_for', '']\n",
      "target: ['××又', 'sell_drugs_to', '家过夜']\n",
      "out: ['胡忠', 'posess', '甲基苯丙胺']\n",
      "target: ['胡修忠', 'traffic_in', '冰毒']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['许某某', 'sell_drugs_to', '蒋某某']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['大黄毛', 'traffic_in', '冰毒']\n",
      "out: ['李某某', 'provide_shelter_for', '']\n",
      "target: ['邓某某', 'posess', '甲基苯丙胺']\n",
      "out: ['吴某', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'traffic_in', '甲基苯丙胺']\n",
      "out: ['某', 'provide_shelter_for', '']\n",
      "target: ['莫某某', 'provide_shelter_for', '陈某']\n",
      "out: ['某某', 'provide_shelter_for', '']\n",
      "target: ['莫某某', 'posess', '甲基苯丙胺']\n",
      "out: ['宋某', 'provide_shelter_for', '']\n",
      "target: ['宋某某', 'provide_shelter_for', '李某']\n",
      "out: ['王某', 'provide_shelter_for', '']\n",
      "target: ['王某', 'sell_drugs_to', '符某某']\n",
      "out: ['吉某某', 'provide_shelter_for', '']\n",
      "target: ['吉地某某', 'sell_drugs_to', '桑某']\n",
      "out: ['徐某某', 'provide_shelter_for', '']\n",
      "target: ['徐某某', 'provide_shelter_for', '刘某']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['董某', 'posess', '甲基苯丙胺']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['吴某某', 'posess', '冰毒']\n",
      "out: ['王某', 'provide_shelter_for', '']\n",
      "target: ['王某', 'sell_drugs_to', '许某']\n",
      "out: ['黄某某某某', 'provide_shelter_for', '']\n",
      "target: ['黄某某', 'provide_shelter_for', '覃某某']\n",
      "out: ['匡某胺', 'provide_shelter_for', '']\n",
      "target: ['匡某', 'sell_drugs_to', '曹某甲']\n",
      "out: ['', 'posess', '麻古']\n",
      "target: ['温某某', 'posess', '麻古']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['明某', 'posess', '甲基苯丙胺片剂']\n",
      "out: ['', 'posess', '甲基苯丙胺']\n",
      "target: ['韩×', 'provide_shelter_for', '崔××']\n",
      "out: ['贺某', 'provide_shelter_for', '']\n",
      "target: ['贺某', 'provide_shelter_for', '孟元亮']\n",
      "out: ['某某', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'posess', '冰毒']\n",
      "out: ['某某某某某', 'provide_shelter_for', '']\n",
      "target: ['曾某某', 'provide_shelter_for', '王某某']\n",
      "out: ['徐某某', 'provide_shelter_for', '']\n",
      "target: ['徐某', 'provide_shelter_for', '赵某']\n",
      "19128.000000001 330.000000001 330.000000001\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "| End of Epoch  2 | Elapsed Time    00:01:03 | Validation Loss 1.008 | Precision 0.252 | Recall 0.252 | F1 0.252 |\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "out: ['吴某某', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'posess', '甲基苯丙胺']\n",
      "127.000000001 3.000000001 3.000000001\n",
      "out: ['康某某', 'provide_shelter_for', '郄某某']\n",
      "target: ['平山县', 'sell_drugs_to', '一天，']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['年4', 'sell_drugs_to', '2个给']\n",
      "out: ['宋xx', 'provide_shelter_for', '']\n",
      "target: ['宋xx', 'posess', '甲基苯丙胺']\n",
      "out: ['段某某', 'provide_shelter_for', '阮敏']\n",
      "target: ['根按照', 'sell_drugs_to', '阮长敏']\n",
      "out: ['马某某某', 'provide_shelter_for', '马某某某']\n",
      "target: ['马某', 'provide_shelter_for', '宾某']\n",
      "out: ['马某某某', 'provide_shelter_for', '马某某某']\n",
      "target: ['马某', 'provide_shelter_for', '喻某某']\n",
      "out: ['梁xx', 'provide_shelter_for', '吴xx']\n",
      "target: ['，用刀', 'traffic_in', '量后，']\n",
      "out: ['钟某', 'provide_shelter_for', '林某']\n",
      "target: ['钟某', 'provide_shelter_for', '陈某乙']\n",
      "out: ['赵xx', 'provide_shelter_for', 'xxx']\n",
      "target: ['赵xx', 'provide_shelter_for', '彭xx']\n",
      "out: ['朱某某', 'provide_shelter_for', '']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['朱某某', 'provide_shelter_for', '']\n",
      "target: ['朱某某', 'posess', '甲基苯丙胺片剂']\n",
      "out: ['冯某某', 'provide_shelter_for', '王某某']\n",
      "target: ['冯某某', 'sell_drugs_to', '王某某']\n",
      "out: ['长友', 'traffic_in', '氯胺酮']\n",
      "target: ['胡长友', 'posess', '大麻']\n",
      "out: ['张某', 'provide_shelter_for', '张某']\n",
      "target: ['张某', 'posess', '甲基苯丙胺']\n",
      "out: ['武某某片', 'provide_shelter_for', '']\n",
      "target: ['武某某', 'posess', '咖啡因']\n",
      "out: ['陈某湘', 'provide_shelter_for', '陈某']\n",
      "target: ['陈某湘', 'provide_shelter_for', '彭某花']\n",
      "out: ['方某', 'provide_shelter_for', '李某']\n",
      "target: ['方某', 'provide_shelter_for', '潘某']\n",
      "out: ['杨某×', 'provide_shelter_for', '杨某×']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['刘某', 'provide_shelter_for', '']\n",
      "target: ['刘某', 'traffic_in', '甲盐酸曲马多']\n",
      "out: ['张某', 'provide_shelter_for', '彭某某']\n",
      "target: ['张某', 'provide_shelter_for', '彭某']\n",
      "out: ['黄某某', 'provide_shelter_for', '朱某某']\n",
      "target: ['黄某某', 'sell_drugs_to', '朱某某']\n",
      "out: ['牟某某古', 'provide_shelter_for', '牟某某']\n",
      "target: ['牟某某', 'provide_shelter_for', '黄金林']\n",
      "out: ['代某', 'provide_shelter_for', '谢某']\n",
      "target: ['代某', 'sell_drugs_to', '谢某']\n",
      "out: ['龙某', 'provide_shelter_for', '']\n",
      "target: ['龙某', 'posess', '麻古']\n",
      "out: ['吴某某忠', 'provide_shelter_for', '钟某']\n",
      "target: ['吴某某', 'traffic_in', '冰毒']\n",
      "out: ['代某某', 'provide_shelter_for', '赖某']\n",
      "target: ['代某某', 'provide_shelter_for', '赖某']\n",
      "out: ['胡某某', 'provide_shelter_for', '夏某某']\n",
      "target: ['胡某某', 'provide_shelter_for', '夏某某']\n",
      "out: ['某', 'provide_shelter_for', '李某某']\n",
      "target: ['李某某', 'provide_shelter_for', '姜某']\n",
      "out: ['项某', 'provide_shelter_for', '海XX']\n",
      "target: ['项某', 'provide_shelter_for', '张某']\n",
      "out: ['郑某某', 'provide_shelter_for', '张某某']\n",
      "target: ['郑某某', 'provide_shelter_for', '王某']\n",
      "5431.000000001 93.000000001 93.000000001\n",
      "out: ['赵某', 'provide_shelter_for', '莫某']\n",
      "target: ['获，', 'provide_shelter_for', '后锡']\n",
      "out: ['陈某某', 'provide_shelter_for', '陈某某']\n",
      "target: ['90', 'provide_shelter_for', '90']\n",
      "out: ['梁某', 'provide_shelter_for', '梁某']\n",
      "target: ['梁某', 'posess', '冰毒']\n",
      "out: ['黎某', 'provide_shelter_for', '曾某某']\n",
      "target: ['氯胺', 'posess', '']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['在被', 'sell_drugs_to', '随即']\n",
      "out: ['钟某某', 'provide_shelter_for', '钟某某']\n",
      "target: ['阿俊', 'traffic_in', '冰毒']\n",
      "out: ['钟某某X某某', 'provide_shelter_for', '钟某某X某某']\n",
      "target: ['钟某某', 'posess', '海洛因']\n",
      "out: ['何某某', 'provide_shelter_for', '唐某']\n",
      "target: ['何某某', 'sell_drugs_to', '朱某']\n",
      "out: ['季某某', 'provide_shelter_for', '蔡某某']\n",
      "target: ['季某某', 'traffic_in', '冰毒']\n",
      "out: ['', 'traffic_in', '海洛因']\n",
      "target: ['伊布卡·杜库', 'posess', '海洛因']\n",
      "out: ['纳某某', 'provide_shelter_for', '吕某某']\n",
      "target: ['纳某某', 'sell_drugs_to', '吕某某']\n",
      "out: ['邢某某', 'provide_shelter_for', '陈某']\n",
      "target: ['邢某某', 'provide_shelter_for', '田某线']\n",
      "out: ['黄某', 'provide_shelter_for', '罗某']\n",
      "target: ['黄某', 'sell_drugs_to', '罗某']\n",
      "out: ['覃某', 'provide_shelter_for', '林某']\n",
      "target: ['覃某', 'traffic_in', '氯胺酮']\n",
      "out: ['王XX', 'provide_shelter_for', '王XXX']\n",
      "target: ['王XX', 'provide_shelter_for', '向X']\n",
      "out: ['徐某', 'provide_shelter_for', '孙某某']\n",
      "target: ['徐某', 'sell_drugs_to', '孙某某']\n",
      "out: ['程某某因弟', 'provide_shelter_for', '程某某弟']\n",
      "target: ['程明开程某某', 'provide_shelter_for', '程某3']\n",
      "out: ['何某', 'provide_shelter_for', '张某']\n",
      "target: ['何某', 'traffic_in', '冰毒']\n",
      "out: ['谢某', 'provide_shelter_for', '李某乙']\n",
      "target: ['谢某', 'provide_shelter_for', '李某甲']\n",
      "out: ['韩某某某某', 'provide_shelter_for', '韩某某某某']\n",
      "target: ['韩某某', 'sell_drugs_to', '刘某某']\n",
      "out: ['张某甲', 'provide_shelter_for', '娄某']\n",
      "target: ['张某甲', 'provide_shelter_for', '娄某']\n",
      "out: ['', 'provide_shelter_for', '吴某']\n",
      "target: ['吴某', 'posess', '甲基苯丙胺']\n",
      "out: ['郭某', 'provide_shelter_for', '苏某']\n",
      "target: ['郭某', 'provide_shelter_for', '刘某某']\n",
      "9463.000000001 162.000000001 162.000000001\n",
      "out: ['欧某某因', 'provide_shelter_for', '某某']\n",
      "target: ['员当场', 'posess', '条、吸']\n",
      "out: ['翁某某', 'provide_shelter_for', '']\n",
      "target: ['获的用', 'posess', '丙胺和']\n",
      "out: ['黄××', 'provide_shelter_for', '罗×']\n",
      "target: ['黄××', 'traffic_in', '海洛因']\n",
      "out: ['李某某', 'provide_shelter_for', '陈某']\n",
      "target: ['陈美燕', 'sell_drugs_to', '邹某某']\n",
      "out: ['罗某', 'provide_shelter_for', '罗某涛']\n",
      "target: ['罗某', 'traffic_in', '冰毒']\n",
      "out: ['刘某', 'provide_shelter_for', '刘某']\n",
      "target: ['刘某', 'posess', '氯胺酮']\n",
      "out: ['曾某', 'provide_shelter_for', '林某某']\n",
      "target: ['曾某', 'provide_shelter_for', '林某某']\n",
      "out: ['周某', 'provide_shelter_for', '周某']\n",
      "target: ['周某', 'traffic_in', '麻果']\n",
      "out: ['王某甲', 'provide_shelter_for', '王某']\n",
      "target: ['王某甲', 'provide_shelter_for', '王某']\n",
      "out: ['谭某某某', 'provide_shelter_for', '谭某某某']\n",
      "target: ['谭某', 'provide_shelter_for', '廖某']\n",
      "out: ['丁某', 'provide_shelter_for', '张某']\n",
      "target: ['丁某', 'traffic_in', '冰毒']\n",
      "out: ['潘某某仙仙', 'provide_shelter_for', '']\n",
      "target: ['潘某某', 'posess', '神仙水']\n",
      "out: ['张×', 'provide_shelter_for', '马×']\n",
      "target: ['张×', 'provide_shelter_for', '史×']\n",
      "out: ['伍某', 'provide_shelter_for', '陈某某某某']\n",
      "target: ['伍某大', 'sell_drugs_to', '陈某某']\n",
      "out: ['谢某', 'provide_shelter_for', '李某乙']\n",
      "target: ['谢某', 'provide_shelter_for', '彭某']\n",
      "out: ['金某某', 'provide_shelter_for', '朴某某']\n",
      "target: ['金某某', 'provide_shelter_for', '朴某某']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12059.000000001 210.000000001 210.000000001\n",
      "out: ['李某某×', 'provide_shelter_for', '某某']\n",
      "target: ['××又', 'sell_drugs_to', '家过夜']\n",
      "out: ['胡忠', 'traffic_in', '']\n",
      "target: ['胡修忠', 'traffic_in', '冰毒']\n",
      "out: ['许某某', 'provide_shelter_for', '蒋某某']\n",
      "target: ['许某某', 'sell_drugs_to', '蒋某某']\n",
      "out: ['辛某某', 'provide_shelter_for', '']\n",
      "target: ['大黄毛', 'traffic_in', '冰毒']\n",
      "out: ['邓某某', 'provide_shelter_for', '李某']\n",
      "target: ['邓某某', 'posess', '甲基苯丙胺']\n",
      "out: ['吴某某', 'provide_shelter_for', '']\n",
      "target: ['吴某某', 'traffic_in', '甲基苯丙胺']\n",
      "out: ['莫某某', 'provide_shelter_for', '王某']\n",
      "target: ['莫某某', 'posess', '甲基苯丙胺']\n",
      "out: ['莫某某', 'provide_shelter_for', '王某']\n",
      "target: ['莫某某', 'provide_shelter_for', '陈某']\n",
      "out: ['宋某某某某某', 'provide_shelter_for', '宋某某某某某']\n",
      "target: ['宋某某', 'provide_shelter_for', '李某']\n",
      "out: ['王某', 'provide_shelter_for', '符某某']\n",
      "target: ['王某', 'sell_drugs_to', '符某某']\n",
      "out: ['吉地某某', 'provide_shelter_for', '孙某']\n",
      "target: ['吉地某某', 'sell_drugs_to', '桑某']\n",
      "out: ['徐某某', 'provide_shelter_for', '刘某']\n",
      "target: ['徐某某', 'provide_shelter_for', '刘某']\n",
      "out: ['吴某某', 'posess', '甲基苯丙胺']\n",
      "target: ['吴某某', 'posess', '冰毒']\n",
      "out: ['', 'provide_shelter_for', '董某']\n",
      "target: ['董某', 'posess', '甲基苯丙胺']\n",
      "out: ['王某某', 'provide_shelter_for', '张某']\n",
      "target: ['王某', 'sell_drugs_to', '许某']\n",
      "out: ['黄某某某', 'provide_shelter_for', '黄某某某']\n",
      "target: ['黄某某', 'provide_shelter_for', '覃某某']\n",
      "out: ['匡某', 'provide_shelter_for', '曹某']\n",
      "target: ['匡某', 'sell_drugs_to', '曹某甲']\n",
      "out: ['温某某', 'provide_shelter_for', '某某某某某']\n",
      "target: ['温某某', 'posess', '麻古']\n",
      "out: ['', 'provide_shelter_for', 'X']\n",
      "target: ['明某', 'posess', '甲基苯丙胺片剂']\n",
      "out: ['韩×', 'provide_shelter_for', '崔××']\n",
      "target: ['韩×', 'provide_shelter_for', '崔××']\n",
      "out: ['贺某', 'provide_shelter_for', '甲亮']\n",
      "target: ['贺某', 'provide_shelter_for', '孟元亮']\n",
      "out: ['某某', 'provide_shelter_for', '李某某']\n",
      "target: ['李某某', 'posess', '冰毒']\n",
      "out: ['曾某某某某某某某某', 'provide_shelter_for', '曾某某某某某某某某']\n",
      "target: ['曾某某', 'provide_shelter_for', '王某某']\n",
      "out: ['徐某某', 'provide_shelter_for', '徐某某']\n",
      "target: ['徐某', 'provide_shelter_for', '赵某']\n",
      "15957.000000001 282.000000001 282.000000001\n",
      "out: ['某', 'provide_shelter_for', '王某']\n",
      "target: ['法鉴', 'sell_drugs_to', '份。当']\n",
      "out: ['林某', 'provide_shelter_for', '李某']\n",
      "target: ['号门口', 'sell_drugs_to', '深圳']\n",
      "out: ['甲基某某', 'provide_shelter_for', '陈某某']\n",
      "target: ['吸食甲', 'provide_shelter_for', '查获陈']\n",
      "out: ['肖某', 'provide_shelter_for', '陈某某']\n",
      "target: ['肖某', 'sell_drugs_to', '张某丙']\n",
      "out: ['朱某某', 'provide_shelter_for', '朱某']\n",
      "target: ['朱某某', 'provide_shelter_for', '朱某1']\n",
      "out: ['', 'provide_shelter_for', '姚某某']\n",
      "target: ['在房间', 'provide_shelter_for', '在长沙']\n",
      "out: ['章胜××××', 'traffic_in', '氯胺酮']\n",
      "target: ['汪章胜', 'posess', '大麻叶']\n",
      "out: ['邓某', 'provide_shelter_for', '']\n",
      "target: ['邓某', 'posess', '甲基苯丙胺']\n",
      "out: ['曹某', 'provide_shelter_for', '罗某']\n",
      "target: ['曹某', 'provide_shelter_for', '张某\"4']\n",
      "out: ['', 'provide_shelter_for', '杨某']\n",
      "target: ['杨某', 'posess', '甲基苯丙胺']\n",
      "out: ['钱某某X', 'provide_shelter_for', '钱某某X']\n",
      "target: ['钱某某', 'posess', '甲基苯丙胺']\n",
      "out: ['李某某因', 'provide_shelter_for', '']\n",
      "target: ['李某某', 'posess', '甲基苯丙胺']\n",
      "out: ['郑某某某', 'provide_shelter_for', '郑某某某']\n",
      "target: ['郑某', 'sell_drugs_to', '苏某某']\n",
      "out: ['甘某', 'provide_shelter_for', '赵某']\n",
      "target: ['甘某', 'provide_shelter_for', '赵某']\n",
      "out: ['刘某某', 'provide_shelter_for', '']\n",
      "target: ['刘某某', 'posess', '甲基苯丙胺']\n",
      "out: ['简某某', 'provide_shelter_for', '陈某']\n",
      "target: ['简某某', 'provide_shelter_for', '杨某某']\n",
      "19128.000000001 330.000000001 330.000000001\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "| End of Epoch  3 | Elapsed Time    00:01:34 | Validation Loss 0.939 | Precision 0.403 | Recall 0.403 | F1 0.403 |\n",
      "----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "lr = lr\n",
    "all_val_loss = []\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "\n",
    "# At any point you can hit Ctrl + C to break out of training early.\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    print(\"-\" * 118)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train()\n",
    "        val_loss, precision, recall, f1 = evaluate(val_data_groups) #评估的是验证集\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"-\" * 118)\n",
    "        print(\"| End of Epoch {:2d} | Elapsed Time {:s} | Validation Loss {:5.3f} | Precision {:5.3f} \"\n",
    "              \"| Recall {:5.3f} | F1 {:5.3f} |\".format(epoch, time_display(elapsed),\n",
    "                                                       val_loss, precision, recall, f1))\n",
    "        print(\"-\" * 118)\n",
    "\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            lr = lr / 4.0\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_precision.append(precision)\n",
    "        all_recall.append(recall)\n",
    "        all_f1.append(f1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 118)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "\n",
    "with open(\"record-batchsize64-epochs30-lr4.tsv\", \"wt\", encoding=\"utf-8\") as f:\n",
    "    for idx in range(len(all_val_loss)):\n",
    "        f.write(\"{:d}\\t{:5.3f}\\t{:5.3f}\\t{:5.3f}\\t{:5.3f}\\n\"\n",
    "                .format(idx+1, all_val_loss[idx], all_precision[idx], all_recall[idx], all_f1[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(torch.tensor(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/my_train.pk', 'rb') as f1:\n",
    "    train_data = pickle.load(f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/my_train.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = train_data[0][1]\n",
    "\n",
    "outsent = list(lines[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 处理tagset\n",
    "tag_set = Index()#定义对象\n",
    "tag_set.load(\"../data/my_tag2id.txt\")#读文件  标记-id\n",
    "\n",
    "### 处理relation\n",
    "relation_labels = Index()#定义对象\n",
    "relation_labels.load('../data/my_relation_labels.txt')#读文件   关系标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity1:  [25, 26, 27]\n",
      "['简', '某', '某']\n",
      "['简', '某', '某']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['简某某', 'provide_shelter_for', '简某某']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_get_triplets(tags,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'机'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['公', '诉', '机', '关', '指', '控', '，', '2', '0', '1', '5', '年', '1', '1', '月', '份', '的', '一', '天', '晚', '上', '，', '被', '告', '人', '简', '某', '某', '容', '留', '陈', '某', '、', '吴', '某', '、', '杨', '某', '某', '、', '张', '某', '、', '伍', '某', '某', '在', '简', '某', '某', '家', '一', '楼', '卧', '室', '，', '以', '烫', '吸', '的', '方', '式', '吸', '食', '甲', '基', '苯', '丙', '胺', '（', '冰', '毒', '）', '。']\n"
     ]
    }
   ],
   "source": [
    "print(outsent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2193"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charset['我喜欢你']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CharEncoder(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Input:  (batch_size, seq_len, char_features)\n",
    "#     \"\"\"\n",
    "#     def __init__(self, weight, channels, kernel_size, dropout, emb_dropout):  #weight 是word_embedding\n",
    "#         super(CharEncoder, self).__init__()\n",
    "#         self.embed = nn.Embedding.from_pretrained(weight, freeze=False)    ##加载词向量\n",
    "#         self.drop = nn.Dropout(emb_dropout)\n",
    "#         self.conv_net = ConvNet(channels, kernel_size, dropout, dilated=True, residual=False)\n",
    "#         #print(weight.size(0),weight.size(1))\n",
    "#     def forward(self,  char_input):\n",
    "#         # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\n",
    "#         #  -> (batch_size, seq_len, embedding_size + char_features)\n",
    "#         #  -> (batch_size, embedding_size + char_features, seq_len)\n",
    "#         embeddings=self.embed(char_input)\n",
    "# #         embeddings = torch.cat((embeddings, char_input), 2)                     ### 将字与词连接起来，以第2维度连接起来\n",
    "#         embeddings=embeddings.transpose(1, 2).contiguous()                      ### 矩阵再次转置\n",
    "\n",
    "#         #print(\"embeddings:----------\",embeddings.size())\n",
    "\n",
    "#         # (batch_size, embedding_size + char_features, seq_len) -> (batch_size, conv_size, seq_len)\n",
    "#         conv_out = self.conv_net(self.drop(embeddings))\n",
    "\n",
    "#         # torch.cat(embeddings, conv_out), 1) ==>(batch_size, embedding_size + char_features, seq_len) -> (batch_size, conv_size + embedding_size + char_features, seq_len)\n",
    "#         #  -> (batch_size, seq_len, conv_size + embedding_size + char_features)\n",
    "#         return torch.cat((embeddings, conv_out), 1).transpose(1, 2).contiguous()\n",
    "\n",
    "# char_encoder = CharEncoder(char_embedding, word_channels, word_kernel_size,dropout=dropout, emb_dropout=emb_dropout)\n",
    "\n",
    "# sentences, targets, lengths = get_batch([0,1,2,3,4], train_data)\n",
    "\n",
    "# char_output = char_encoder(sentences)\n",
    "\n",
    "# len(char_output[0])  276\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self,input_size,hidden_dim,output_size,NUM_LAYERS):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.input_size=input_size\n",
    "#         self.hidden_dim = hidden_dim      ###有\n",
    "#         self.output_size=output_size      ### 分为多少类\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_dim, num_layers = NUM_LAYERS)\n",
    "#         self.hidden2label = nn.Linear(hidden_dim, output_size)\n",
    "#         self.init_weight()\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         self.lstm.flatten_parameters()\n",
    "#         #print(self.hidden_dim,self.input_size,self.output_size)\n",
    "#         # self.hidden = self.init_hidden(inputs.size(1))\n",
    "#         self.hidden = self.init_hidden(inputs.size(1))\n",
    "#         lstm_out, self.hidden = self.lstm(inputs,self.hidden)\n",
    "#         #lstm_out, self.hidden = self.lstm(inputs,None)\n",
    "#         y = self.hidden2label(lstm_out)\n",
    "#         return y\n",
    "\n",
    "#     def init_weight(self):\n",
    "#         nn.init.kaiming_uniform_(self.hidden2label.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         return (autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)),\n",
    "#                 autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  weight, char_embedding_size, char_channels, char_kernel_size, num_tag, dropout, emb_dropout):    ##搭建网络结构\n",
    "#         super(Model, self).__init__()\n",
    "\n",
    "#         self.char_encoder = CharEncoder(char_embedding, char_channels, char_kernel_size,dropout=dropout, emb_dropout=emb_dropout)\n",
    "#         self.drop = nn.Dropout(dropout)\n",
    "# #         self.char_conv_size = char_channels[-1]\n",
    "#         self.char_embedding_size = char_embedding_size\n",
    "#         self.char_conv_size = char_channels[-1]\n",
    "#         #self.decoder = nn.Linear(self.char_conv_size+self.word_embedding_size+self.word_conv_size, num_tag)\n",
    "#         self.decoder = Decoder(self.char_embedding_size+self.char_conv_size,    ###输入特征\n",
    "#                                64 + self.char_embedding_size + self.char_conv_size,###隐藏层维度\n",
    "#                                num_tag,NUM_LAYERS=1)\n",
    "\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def forward(self, char_input):\n",
    "#         batch_size = char_input.size(0)  #32\n",
    "#         seq_len = char_input.size(1)    #句子长度\n",
    "# #         char_input=char_input.contiguous()\n",
    "# #         #print(char_input.view(-1, char_input.size(2)).size(0),char_input.view(-1, char_input.size(2)).size(1))##3200*10\n",
    "# #         char_output = self.char_encoder(char_input.view(-1, char_input.size(2))).view(batch_size, seq_len, -1)#char_input.size(2)==20  调用forward方法\n",
    "#         char_output = self.char_encoder(char_input)  ##(batch_size, seq_len, conv_size + embedding_size + char_features)\n",
    "#         y = self.decoder(char_output)\n",
    "\n",
    "#         return F.log_softmax(y, dim=2)\n",
    "# #         return F.log_softmax(y, dim=1)\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         pass\n",
    "\n",
    "# word_embeddings = torch.tensor(np.load(\"../data/char_embedding.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
